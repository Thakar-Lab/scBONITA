from classDefinitions import *
from reproducible_example_code import *
from testSimulation import *
import umap
from ctypes import *
import time
import glob
import pickle as pickle
import argparse as argparse
import os as os
import pandas as pd
import seaborn as sns
from random import sample
import numpy as np
import matplotlib.pyplot as plt
import os.path
from os import path
from pathlib import Path
import re
import shutil
from ast import literal_eval
from matplotlib.backends.backend_pdf import PdfPages

np.set_printoptions(threshold=sys.maxsize)


def processERS_minimalRule(equivsName, allscData):
    """Create an individual from the ERS generated by the local search, for importance score calculation"""
    ersFile = open(str(equivsName), "rb")
    print(equivsName)
    ers = pickle.load(ersFile)
    ersFile.close()
    individual = []
    for i in range(len(ers)):
        ruleSet = ers[i]
        # print(i)
        # print(len(ruleSet))
        # print(ruleSet)
        numOrRules = [sum(ruleSet[j]) for j in range(len(ruleSet))]
        deciderVar = max(numOrRules)  # maximal or rules
        maxOrRules = ruleSet[
            numOrRules.index(deciderVar)
        ]  # rules with maximum or terms
        print("maxOrRules", maxOrRules)
        maxUpstreamNodes = 0
        minimalRule = []
        for orRule in [maxOrRules]:
            print("orRule", orRule)
            if sum(orRule) > 0:
                print(allscData.andNodeList[i])
                print(allscData.nodeList[i])
                # if len(allscData.andNodeList[i]) == 0:
                #    numUpstreamNodes = [[0]]
                # else:
                numUpstreamNodes = [
                    allscData.andNodeList[i][orTerm]
                    for orTerm in range(len(orRule))
                    if orRule[orTerm] == 1
                ]
            else:
                minimalRule = orRule
                continue
            numUpstreamNodes = [len(element) for element in numUpstreamNodes]
            numUpstreamNodes = sum(numUpstreamNodes)
            if numUpstreamNodes > maxUpstreamNodes:
                maxUpstreamNodes = numUpstreamNodes
                minimalRule = orRule
            else:
                maxUpstreamNodes = maxUpstreamNodes
                minimalRule = minimalRule
        # print("maxUpstreamNodes", maxUpstreamNodes)
        individual.extend(minimalRule)
        print("$$")
    return individual


def compareSubpops(graphNames):
    owd = os.getcwd()
    resDF = pd.DataFrame(list(zip([], [])), columns=["In_degree", "Equivs_len"])
    resDF["Node"] = []
    resDF["Number_of_Nodes"] = []
    resDF["Graph"] = []
    resDF["AvgLocalError"] = []
    resDF["taoScore"] = []
    resDF["Out_degree"] = []
    resDF["inOutRatio"] = []
    resDF["importanceScore"] = []
    resDF["Subpop"] = []
    resDF["plainEquivs"] = []
    resDF["bitstringEquivs"] = []
    # graphNames=["hsa04024.graphml", "hsa04630.graphml"] #glob.glob("*.graphml")
    dataName = glob.glob("*binscTest.pickle")[0]

    for graphName in graphNames:
        print(graphName)
        equivs = graphName + "_processed.graphml_equivs1.pickle"

        if (
            Path(dataName).is_file()
            and Path(graphName).is_file()
            and Path(equivs).is_file()
            and Path(graphName + "_processed.graphml_importanceScores.csv").is_file()
        ):

            dataPickle = glob.glob(dataName)[0]
            allscData = pickle.load(open(dataPickle, "rb"))
            graph = nx.read_graphml(graphName)

            errorsName = glob.glob(str(graphName) + "*_localErrors1.pickle")[0]
            localErrors = pickle.load(open(errorsName, "rb"))

            allscData.inherit(
                allscData.pathwayGraphs[graphName],
                removeSelfEdges=False,
                restrictIncomingEdges=False,
            )
            equivs = pickle.load(
                open(graphName + "_processed.graphml_equivs1.pickle", "rb")
            )

            equivs = [tuple(equivs[i]) for i in range(0, len(equivs))]
            # print(equivs)
            equivs_len = [len(equivs[i]) for i in range(0, len(equivs))]

            nodeList = list(allscData.nodeList)
            minimalRules = processERS_minimalRule(
                graphName + "_processed.graphml_equivs1.pickle", allscData
            )
            plainEquivs = {}
            bitstringEquivs = {}
            minimalRulesNodes = {}
            for node in range(0, len(nodeList)):
                plainRules = []
                # start1,end1 = findEnds(allscData, allscData.nodeList[node], equivs[node])
                ers = equivs[node]  # find the bitstring for just this node
                # inEdges = findInEdges(allscData, allscData.nodeList.index(allscData.nodeList[node]))
                for rule in ers:
                    plainRules.append(
                        allscData.writeNode(
                            allscData.nodeList.index(allscData.nodeList[node]),
                            rule,
                            allscData,
                        )
                    )
                plainEquivs[nodeList[node]] = set(plainRules)
                bitstringEquivs[nodeList[node]] = set(
                    tuple(ers[i]) for i in range(0, len(ers))
                )
                minimalRulesNodes[nodeList[node]] = allscData.writeNode(
                    node,
                    minimalRules[
                        allscData.individualParse[node] : allscData.individualParse[
                            node + 1
                        ]
                    ],
                    allscData,
                )
            in_degree = [
                allscData.pathwayGraphs[graphName].in_degree(node) for node in nodeList
            ]
            out_degree = [
                allscData.pathwayGraphs[graphName].out_degree(node) for node in nodeList
            ]
            inOutRatio = [
                float(inDeg + 1) / (outDeg + 1)
                for inDeg, outDeg in zip(in_degree, out_degree)
            ]
            taoScore = {
                key: np.nan for key in nodeList
            }  # ruleScore(nx.read_graphml(graphName))

            # Get importance score
            importanceScoreDF = pd.read_csv(
                graphName + "_processed.graphml_importanceScores.csv"
            )
            importanceScoreDict = {}
            for n in list(importanceScoreDF["Node"]):
                temp = importanceScoreDF[importanceScoreDF.Node.isin({n})]
                importanceScoreDict[n] = list(temp["Importance Score"])[0]

            tempdf = pd.DataFrame(
                list(zip(nodeList, in_degree, out_degree, inOutRatio, equivs_len)),
                columns=["Node", "In_degree", "Out_degree", "inOutRatio", "Equivs_len"],
            )
            tempdf["Graph"] = graphName
            tempdf["Number_of_Nodes"] = str(len(nodeList))
            tempdf["taoScore"] = tempdf["Node"].map(taoScore)
            tempdf["importanceScore"] = tempdf["Node"].map(importanceScoreDict)
            tempdf["AvgLocalError"] = localErrors
            tempdf["plainEquivs"] = tempdf["Node"].map(plainEquivs)
            tempdf["bitstringEquivs"] = tempdf["Node"].map(bitstringEquivs)

            tempdf["minimalRules"] = tempdf["Node"].map(minimalRulesNodes)
            resDF = resDF.append(tempdf, ignore_index=True)  # , sort=False)

        subpop = os.path.basename(str(owd))
        resDF["Subpop"] = subpop
        resDF.to_csv(subpop + "_rule_analysis.csv", index=False)
        print(resDF)


def makePlots():
    resDF = glob.iglob("*_rule_analysis.csv")
    outputDF = pd.concat((pd.read_csv(f) for f in resDF), ignore_index=False)
    outputDF["bitstringEquivs"] = outputDF.bitstringEquivs.apply(literal_eval)
    outputDF["putativeERS"] = outputDF.bitstringEquivs.apply(len)
    print(outputDF)
    print(outputDF.columns)

    outputDF.plot(
        x="inOutRatio",
        y="importanceScore",
        kind="scatter",
        title="(In-degree + 1)/(Out-degree + 1) vs. Importance Score\nCorrelation: "
        + str(outputDF.corr()["inOutRatio"]["importanceScore"]),
    )
    plt.xlabel("(In-degree + 1)/(Out-degree + 1)")
    plt.ylabel("Importance Score")
    plt.savefig("inOutRatio_vs_importanceScore.png")

    outputDF.plot(
        x="Out_degree",
        y="importanceScore",
        kind="scatter",
        title="Out-degree vs. Importance Score\nCorrelation: "
        + str(outputDF.corr()["Out_degree"]["importanceScore"]),
    )
    plt.xlabel("Out-degree")
    plt.ylabel("Importance Score")
    plt.savefig("outDegree_vs_importanceScore.png")

    outputDF.plot(
        x="In_degree",
        y="importanceScore",
        kind="scatter",
        title="In-degree vs. Importance Score\nCorrelation: "
        + str(outputDF.corr()["In_degree"]["importanceScore"]),
    )
    plt.xlabel("In-degree")
    plt.ylabel("Importance Score")
    plt.savefig("inDegree_vs_importanceScore.png")

    sourceNodesDF = outputDF[outputDF["In_degree"] == 0]
    sourceNodesDF.hist(column="importanceScore")
    plt.xlabel("Importance Score")
    plt.ylabel("Frequency")
    plt.title("Importance Score of Source Nodes (In-degree = 0)")
    plt.savefig("sourceNodes_importanceScore.png")

    sourceNodesDF.plot(
        x="inOutRatio",
        y="importanceScore",
        kind="scatter",
        title="For source nodes: (In-degree + 1)/(Out-degree + 1) vs. Importance Score\nCorrelation: "
        + str(sourceNodesDF.corr()["inOutRatio"]["importanceScore"]),
    )
    plt.xlabel("(In-degree + 1)/(Out-degree + 1)")
    plt.ylabel("Importance Score")
    plt.savefig("sourceNodes_inOutRatio_vs_importanceScore.png")

    outputDF.hist(column="importanceScore")
    plt.xlabel("Importance Score")
    plt.ylabel("Frequency")
    plt.title("Distribution of Importance Score of All Nodes")
    plt.savefig("allNodes_importanceScore.png")

    # outputDF.boxplot(column="putativeERS", by="Subpop")
    outputDF2 = outputDF[outputDF.In_degree >= 3]
    print(outputDF2)
    print(outputDF2.shape)
    print(set(outputDF2.Equivs_len))
    # outputDF2.boxplot(column="Equivs_len", by="Subpop", vert=False)
    # plt.savefig('allNodes_ERSsize.png')

    sns.set(style="ticks")
    tempPlot = sns.catplot(
        x="Equivs_len", y="Subpop", data=outputDF2, orient="h", color="grey"
    )  # , kind="boxen"
    tempPlot.set(ylabel="Subpopulation", xlabel="Number of rules in ERS")
    # tempPlot=tempPlot.get_figure()
    tempPlot.savefig("allNodes_ERSsize.png")
    plt.clf()

    sns.set(style="ticks")
    tempPlot = sns.catplot(
        x="putativeERS", y="Subpop", data=outputDF2, orient="h", color="grey"
    )  # , kind="boxen"
    tempPlot.set(ylabel="Subpopulation", xlabel="Number of rules in simplified ERS")
    # plt.xlim(0, 127)
    # tempPlot=tempPlot.get_figure()
    tempPlot.savefig("allNodes_simplifiedERSsize.png")
    plt.clf()

    """
    for network in list(set(outputDF.Graph)):
        print(network)
        outputMat = compareRulesPlot(outputDF, network)
        print(outputMat)
        outputMatDF = pd.DataFrame(outputMat)
        print(outputMatDF)
        outputMatDF.to_csv(str(network)+"_compareRules.csv")
    """

    return outputDF


def compareRulesPlot(outputDF, network):
    # outputDF = pd.read_csv(str(outputDF), index_col=0)
    netDF = outputDF[outputDF.Graph == network]
    print(netDF)
    numberNodes = len(list(set(netDF.Node)))
    outputMatrix = {}
    for subpop1 in list(set(netDF.Subpop)):
        outputMatrix[subpop1] = {}
        for subpop2 in list(set(netDF.Subpop)):
            percentOverlap = 0
            outputMatrix[subpop1][subpop2] = percentOverlap
            for node in list(set(netDF.Node)):
                subpop1_equivs = netDF[netDF["Node"] == node]
                subpop1_equivs = subpop1_equivs[subpop1_equivs["Subpop"] == subpop1]
                subpop1_equivs = set(subpop1_equivs.plainEquivs.tolist())
                subpop2_equivs = netDF[netDF["Node"] == node]
                subpop2_equivs = subpop2_equivs[subpop2_equivs["Subpop"] == subpop2]
                subpop2_equivs = set(subpop2_equivs.plainEquivs.tolist())
                # print(len(subpop1_equivs), len(subpop2_equivs))
                firstMatch = next(
                    (a for a in subpop1_equivs if a in subpop2_equivs), None
                )
                if firstMatch:
                    percentOverlap = 1
                    outputMatrix[subpop1][subpop2] = (
                        percentOverlap + outputMatrix[subpop1][subpop2]
                    )
                else:
                    outputMatrix[subpop1][subpop2] = outputMatrix[subpop1][subpop2]
    return outputMatrix, numberNodes


def parallelCompareRules():
    # outputDF = makePlots()
    # outputDF.to_csv("outputDF.csv", index=True)
    outputDF = pd.read_csv("outputDF.csv", index_col=0)
    for network in list(set(outputDF.Graph)):
        print(network)
        name = network[:-8]
        shellHandle = open(name + "_compareRules.sh", "w+")
        slurmCommands = str(
            "#!/bin/sh\n#SBATCH --partition=standard\n#SBATCH -J "
            + name
            + "\n#SBATCH -o "
            + name
            + ".log\n#SBATCH -t 1:00:00\n#SBATCH -n 1\n#SBATCH -c 1\n#SBATCH --mem=30G\nmodule load anaconda3/2020.07\nsource activate /gpfs/fs2/scratch/mpalshik/completeData_17July2020/envs\nmake\npython parallelRuleCompare.py "
            + str(network)
            + "\n"
        )
        shellHandle.write(slurmCommands)
        shellHandle.close()
        shellCommand = name + "_compareRules.sh"
        print([shellCommand])
        p = subprocess.Popen(["sbatch", shellCommand])


def makeSubpopCompareHeatmaps():
    myfiles = glob.glob("*_compareRules.csv")

    # Replace contrast names with subpopulation names
    subpopNames = {
        "0_subpop": "B cells naive - 1",
        "1_subpop": "T cells CD8 - 1",
        "2_subpop": "T cells CD4 - 1",
        "3_subpop": "T cells CD8/CD4/CD4 naive",
        "4_subpop": "T cells CD8 naive/T cells CD8/ RBCs",
        "5_subpop": "B cells naive - 2",
        "6_subpop": "T cells naive",
        "7_subpop": "T cells CD8 - 2",
        "8_subpop": "T cells CD8 - 3",
        "9_subpop": "NK cells resting",
        "10_subpop": "T cells CD8 - 4",
        "11_subpop": "T cells CD8/NK cells resting",
        "12_subpop": "T cells CD4 memory resting/ T cells CD8",
        "13_subpop": "B cells memory",
        "14_subpop": "Monocytes",
        "15_subpop": "NK cells activated",
    }
    pdf = PdfPages("all_subpop_compare_plots.pdf")
    totalDF = pd.read_csv(myfiles[0], index_col=0)

    print(totalDF)
    i = 0
    for resFile in myfiles:
        if i == 0:
            i = i + 1
        else:
            i = i + 1
            print(resFile)
            resDF = pd.read_csv(resFile, index_col=0)
            totalDF = totalDF.add(resDF, fill_value=0)
            print(totalDF)
    print(totalDF)
    totalDF = totalDF / totalDF.values.max()
    print(totalDF)

    mask = np.zeros_like(totalDF)
    mask[np.triu_indices_from(mask)] = True
    totalDF.columns = [
        subpopNames[subpopNumber] for subpopNumber in list(totalDF.columns)
    ]
    totalDF.index = [subpopNames[subpopNumber] for subpopNumber in list(totalDF.index)]
    totalDF.to_csv("totalDF.csv")
    with sns.axes_style("white"):
        f, ax = plt.subplots(figsize=(11, 11))
        ax = sns.heatmap(
            totalDF,
            mask=mask,
            vmax=0.3,
            square=True,
            linewidths=0.3,
            annot=True,
            cmap="autumn_r",
            fmt=".1f",
        )
        # ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 10)
        # ax.set_yticklabels(ax.get_xmajorticklabels(), fontsize = 10)
        title = str("All networks\n").upper()
        plt.title(title, loc="left")
        plt.xticks(rotation=90)
        ax.patch.set_alpha(None)
        # plt.savefig("allNetworks_subpopCompare.png")
        # plt.clf()
        plt.tight_layout()
        pdf.savefig()

    for resFile in myfiles:
        resDF = pd.read_csv(resFile, index_col=0)
        resDF.columns = [
            subpopNames[subpopNumber] for subpopNumber in list(resDF.columns)
        ]
        resDF.index = [subpopNames[subpopNumber] for subpopNumber in list(resDF.index)]
        resDF = resDF / resDF.values.max()
        pathID = resFile[:8]
        pathName = getPathwayName(pathID).replace(" - Homo sapiens (human)", "")
        # sns.set_context("paper", rc={"font.size":14,"axes.titlesize":14,"axes.labelsize":14})
        sns.set_context("paper")
        sns.set(font_scale=0.8)
        # ax = sns.clustermap(resDF, square=True, linewidth=0.3, yticklabels=True, figsize=(12, 12), cmap="vlag")
        # plt.xticks(rotation=90)
        # title = str(pathName+'\n').upper()
        # plt.title(title, loc='left')
        # ax.ax_col_dendrogram.set_visible(True)

        mask = np.zeros_like(resDF)
        mask[np.triu_indices_from(mask)] = True
        with sns.axes_style("white"):
            f, ax = plt.subplots(figsize=(11, 11))
            ax = sns.heatmap(
                resDF,
                mask=mask,
                vmax=0.3,
                square=True,
                linewidths=0.3,
                annot=True,
                cmap="autumn_r",
                fmt=".1f",
            )
            # ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 10)
            # ax.set_yticklabels(ax.get_xmajorticklabels(), fontsize = 10)
            title = str(pathName + "\n").upper()
            plt.title(title, loc="left")
            plt.xticks(rotation=90)
            ax.patch.set_alpha(None)
            # plt.savefig(pathID+"_subpopCompare.png")
            # plt.clf()
            plt.tight_layout()
            pdf.savefig()

    pdf.close()


def makeUMAPplots_byAttractor(networkList):
    # Make UMAP plots

    # Read in PCA embeddings
    completeData = pd.read_csv("cell_embeddings.csv", index_col=0)
    print(completeData.head())

    reducer = umap.UMAP()
    embedding = reducer.fit_transform(completeData.values)
    print(embedding.shape)
    """
    #Read in metadata
    #Use Seurat cluster labels
    clusterLabels = pd.read_csv("allMetaData.txt", index_col = 0)
    clusterLabels = pd.DataFrame(clusterLabels['res.1.5'])
    clusterLabels.columns = ["cluster7"]
    print(clusterLabels.head())


    #Add metadata to expression dataframe
    labeledData = completeData.merge(clusterLabels, left_index=True, right_index=True)
    print(labeledData.head())
    print(labeledData.cluster7.value_counts())

    plt.scatter(
        embedding[:, 0],
        embedding[:, 1],
        c=labeledData.cluster7,
        cmap='Spectral',
        s = 0.1)
    plt.gca().set_aspect('equal', 'datalim')
    plt.colorbar(boundaries=np.arange(17)-0.5).set_ticks(np.arange(16))
    plt.title('Seurat labels', fontsize=14)
    plt.savefig('seurat_labels.pdf', bbox_inches='tight')
    plt.close()
    """
    # Use one network's attractors as labels
    # pdf = PdfPages('attractor_label_plots.pdf')
    for orig_network in networkList:
        networkName = getPathwayName(orig_network)
        network = orig_network + ".graphml_processed.graphml_attractorDistance.csv"
        if os.path.exists(network):
            print(network)
            featureDF = pd.read_csv(network, index_col=0)
            clusterLabels = pd.DataFrame(featureDF["decider"])
            clusterLabels.columns = ["decider"]
            if len(set(clusterLabels.decider)) > 1:
                labeledData = completeData.merge(
                    clusterLabels, left_index=True, right_index=True
                )
                print(labeledData.head())
                plt.scatter(
                    embedding[:, 0],
                    embedding[:, 1],
                    c=labeledData.decider,
                    cmap="Set1",
                    s=0.1,
                )
                plt.gca().set_aspect("equal", "datalim")
                plt.colorbar(
                    boundaries=np.arange(len(set(labeledData.decider))) - 0.5
                ).set_ticks(np.arange(len(set(labeledData.decider))))
                plt.title(str(networkName), fontsize=12)
                plt.savefig(
                    "bonita_labels_" + orig_network + ".pdf", bbox_inches="tight"
                )
                plt.close()
                # pdf.savefig()
    # pdf.close()


if __name__ == "__main__":
    # parser = argparse.ArgumentParser()
    # parser.add_argument("compareSubpops")
    # parser.add_argument("makePlots")
    # results = parser.parse_args()
    # compareSubpopsVal=results.compareSubpops
    # makePlots=results.makePlots

    # if compareSubpops=="True":
    #    #compareSubpops()
    #    print(str(compareSubpops))

    # Step 1:
    # compareSubpops()

    # Step 2:
    # outputDF = makePlots()
    # outputDF.to_csv("outputDF.csv", index=True)

    # Step 3:
    # parallelCompareRules()

    # Step 4:
    # makeSubpopCompareHeatmaps()
    # print("done")

    # outputDF = pd.read_csv("outputDF.csv", index_col=0)
    # outputDF["plainEquivs"] = outputDF.plainEquivs.apply(literal_eval)
    # outputDF["plainEquivs"] = outputDF.plainEquivs.apply(list)

    # print(outputDF.head())

    """
    #print("find networks, any subpopulation with any restricted rules")
    print("find networks with rules that differ between subpopulations")
    for network in list(set(outputDF.Graph)):
        netDF = outputDF[outputDF.Graph == network]
        indeg_3_DF = netDF[netDF.In_degree == 3]
        if (indeg_3_DF.Equivs_len < 127).any():
            print(network[:-8], getPathwayName(network[:-8]))
            print("All subpops: ", list(set(indeg_3_DF.Subpop)))
            temp = indeg_3_DF[indeg_3_DF.Equivs_len < 127]
            print("Subpops with restricted rules: " , list(set(temp.Subpop)))
            #print(temp.shape)
            #print(list(set(temp.Node)))
            #print(list(set(temp.Subpop)))
            #print("****")
            for node in list(set(temp.Node)):
                print("Node: ", node)
                equivs = temp[temp.Node == node]
                allEquivs = {}
                for subpop in list(set(equivs.Subpop)):
                    allEquivs[subpop] = equivs.plainEquivs[equivs.Subpop==subpop].tolist()
                    print(subpop, len(allEquivs[subpop][0]))#, allEquivs[subpop][0])

                #print("Number of unique rule sets", len(allEquivs))

            print("****")

    print("**********\n")
    """

    """
    print("find networks where 14_subpop had restricted rules")
    indeg_3_DF = outputDF[outputDF.In_degree == 3]
    indeg_3_DF = indeg_3_DF[indeg_3_DF.Equivs_len < 127]
    monocyteDF = indeg_3_DF[indeg_3_DF.Subpop == "14_subpop"]
    monocyteDF["pathwayName"] = [getPathwayName(netID[:-8]) for netID in monocyteDF.Graph.to_list()]
    print(monocyteDF.shape)
    print(monocyteDF)
    monocyteDF.to_csv("monocyteDF.csv")


    print("find networks where 11_subpop had restricted rules")
    indeg_3_DF = outputDF[outputDF.In_degree == 3]
    indeg_3_DF = indeg_3_DF[indeg_3_DF.Equivs_len < 127]
    monocyteDF = indeg_3_DF[indeg_3_DF.Subpop == "11_subpop"]
    monocyteDF["pathwayName"] = [getPathwayName(netID[:-8]) for netID in monocyteDF.Graph.to_list()]
    print(monocyteDF.shape)
    print(monocyteDF)
    monocyteDF.to_csv("subpop_11_restrictedRules.csv")

    print("find networks where any subpop had restricted rules")
    indeg_3_DF = outputDF[outputDF.In_degree == 3]
    indeg_3_DF = indeg_3_DF[indeg_3_DF.Equivs_len < 127]
    indeg_3_DF["pathwayName"] = [getPathwayName(netID[:-8]) for netID in indeg_3_DF.Graph.to_list()]
    print(indeg_3_DF.shape)
    print(indeg_3_DF)
    indeg_3_DF.to_csv("all_subpops_restrictedRules.csv")
    """

    # Make network figure for hsa 04625 from 11_subpop (C type receptor signaling pathway)
    """
    original = nx.read_graphml("/mnt/d/GitHub/fuzzyRNA/completeData_17July2020/11_subpop/hsa04625_IS_AS_vs_nonAS.graphml")
    nx.set_node_attributes(original,name='Display Name', values={k: k for k in original.nodes()})
    nx.set_node_attributes(original,name='andNode',values={k: 0 for k in original.nodes()})
    ruleFile = "/mnt/d/GitHub/fuzzyRNA/completeData_17July2020/11_subpop/hsa04625.graphml_processed.graphml_rules_LS.txt"
    ruleFH = open(ruleFile, "r")
    rules = ruleFH.readlines()
    ruleGraph = Get_expanded_network(rules)
    RAval = nx.get_node_attributes(original, "relativeAbundance")
    nx.set_node_attributes(ruleGraph,name='relativeAbundance',values={k: RAval[k] if k in list(original.nodes()) else 0. for k in list(ruleGraph.nodes())})
    pathImportances = nx.get_node_attributes(original, "importanceScore")
    nx.set_node_attributes(ruleGraph,name='importancsScore', values={k: pathImportances[k] if k in list(original.nodes()) else 0. for k in list(ruleGraph.nodes())})
    impactScore = nx.get_node_attributes(original, "impactScore")
    nx.set_node_attributes(ruleGraph,name='impactScore', values={k: impactScore[k] if k in list(original.nodes()) else 0. for k in list(ruleGraph.nodes())})

    nx.write_graphml(ruleGraph,"testRuleGraph.graphml")
    """

    """
    #Make network figures: 3c, 4c

    subpopNames = {"0_subpop" : "B cells naive - 1", "1_subpop" : "T cells CD8 - 1", "2_subpop" : "T cells CD4 - 1", "3_subpop" : "T cells CD8/CD4/CD4 naive", "4_subpop" : "T cells CD8 naive/T cells CD8/ RBCs", "5_subpop" : "B cells naive - 2", "6_subpop" : "T cells naive", "7_subpop" : "T cells CD8 - 2", "8_subpop" : "T cells CD8 - 3", "9_subpop" : "NK cells resting", "10_subpop"  : "T cells CD8 - 4", "11_subpop" : "T cells CD8/NK cells resting", "12_subpop" : "T cells CD4 memory resting/ T cells CD8", "13_subpop" : "B cells memory", "14_subpop" : "Monocytes", "15_subpop" : "NK cells activated"}
    paths = glob.glob('*/')
    for subpop in paths:
        #print(str(subpop))
        if str(subpop)[:-1] in subpopNames.keys():
            print(subpop)

            #Figure 3
            #AGE-RAGE:

            original = nx.read_graphml(os.getcwd()+"/"+subpop+"/hsa04933_IS_AS_vs_nonAS.graphml")
            nx.set_node_attributes(original,name='Display Name', values={k: k for k in original.nodes()})
            nx.set_node_attributes(original,name='andNode',values={k: 0 for k in original.nodes()})
            ruleFile = os.getcwd()+"/"+subpop+"/hsa04933.graphml_processed.graphml_rules_LS.txt"
            ruleFH = open(ruleFile, "r")
            rules = ruleFH.readlines()
            ruleGraph = Get_expanded_network(rules)
            RAval = nx.get_node_attributes(original, "relativeAbundance")
            nx.set_node_attributes(ruleGraph,name='relativeAbundance',values={k: RAval[k] if k in list(original.nodes()) else 0. for k in list(ruleGraph.nodes())})
            pathImportances = nx.get_node_attributes(original, "importanceScore")
            nx.set_node_attributes(ruleGraph,name='importancsScore', values={k: pathImportances[k] if k in list(original.nodes()) else 0. for k in list(ruleGraph.nodes())})
            impactScore = nx.get_node_attributes(original, "impactScore")
            nx.set_node_attributes(ruleGraph,name='impactScore', values={k: impactScore[k] if k in list(original.nodes()) else 0. for k in list(ruleGraph.nodes())})
            nx.write_graphml(ruleGraph,subpop[:-1]+"_AGERAGE_ruleGraph.graphml")

            #Chemokine signaling
            original = nx.read_graphml(os.getcwd()+"/"+subpop+"/hsa04062_IS_AS_vs_nonAS.graphml")
            nx.set_node_attributes(original,name='Display Name', values={k: k for k in original.nodes()})
            nx.set_node_attributes(original,name='andNode',values={k: 0 for k in original.nodes()})
            ruleFile = os.getcwd()+"/"+subpop+"/hsa04062.graphml_processed.graphml_rules_LS.txt"
            ruleFH = open(ruleFile, "r")
            rules = ruleFH.readlines()
            ruleGraph = Get_expanded_network(rules)
            RAval = nx.get_node_attributes(original, "relativeAbundance")
            nx.set_node_attributes(ruleGraph,name='relativeAbundance',values={k: RAval[k] if k in list(original.nodes()) else 0. for k in list(ruleGraph.nodes())})
            pathImportances = nx.get_node_attributes(original, "importanceScore")
            nx.set_node_attributes(ruleGraph,name='importancsScore', values={k: pathImportances[k] if k in list(original.nodes()) else 0. for k in list(ruleGraph.nodes())})
            impactScore = nx.get_node_attributes(original, "impactScore")
            nx.set_node_attributes(ruleGraph,name='impactScore', values={k: impactScore[k] if k in list(original.nodes()) else 0. for k in list(ruleGraph.nodes())})
            nx.write_graphml(ruleGraph,subpop[:-1]+"_chemokine_hsa04062_ruleGraph.graphml")

            #Figure 4
            #4a

            #C type lectin signaling hsa04625
            original = nx.read_graphml(os.getcwd()+"/"+subpop+"/hsa04625_IS_AS_vs_nonAS.graphml")
            nx.set_node_attributes(original,name='Display Name', values={k: k for k in original.nodes()})
            nx.set_node_attributes(original,name='andNode',values={k: 0 for k in original.nodes()})
            ruleFile = os.getcwd()+"/"+subpop+"/hsa04625.graphml_processed.graphml_rules_LS.txt"
            ruleFH = open(ruleFile, "r")
            rules = ruleFH.readlines()
            ruleGraph = Get_expanded_network(rules)
            RAval = nx.get_node_attributes(original, "relativeAbundance")
            nx.set_node_attributes(ruleGraph,name='relativeAbundance',values={k: RAval[k] if k in list(original.nodes()) else 0. for k in list(ruleGraph.nodes())})
            pathImportances = nx.get_node_attributes(original, "importanceScore")
            nx.set_node_attributes(ruleGraph,name='importancsScore', values={k: pathImportances[k] if k in list(original.nodes()) else 0. for k in list(ruleGraph.nodes())})
            impactScore = nx.get_node_attributes(original, "impactScore")
            nx.set_node_attributes(ruleGraph,name='impactScore', values={k: impactScore[k] if k in list(original.nodes()) else 0. for k in list(ruleGraph.nodes())})
            nx.write_graphml(ruleGraph,subpop[:-1]+"_c_type_lectin_hsa04625_ruleGraph.graphml")

            #Cellular senescence hsa04218
            original = nx.read_graphml(os.getcwd()+"/"+subpop+"/hsa04218_IS_AS_vs_nonAS.graphml")
            nx.set_node_attributes(original,name='Display Name', values={k: k for k in original.nodes()})
            nx.set_node_attributes(original,name='andNode',values={k: 0 for k in original.nodes()})
            ruleFile = os.getcwd()+"/"+subpop+"/hsa04218.graphml_processed.graphml_rules_LS.txt"
            ruleFH = open(ruleFile, "r")
            rules = ruleFH.readlines()
            ruleGraph = Get_expanded_network(rules)
            RAval = nx.get_node_attributes(original, "relativeAbundance")
            nx.set_node_attributes(ruleGraph,name='relativeAbundance',values={k: RAval[k] if k in list(original.nodes()) else 0. for k in list(ruleGraph.nodes())})
            pathImportances = nx.get_node_attributes(original, "importanceScore")
            nx.set_node_attributes(ruleGraph,name='importancsScore', values={k: pathImportances[k] if k in list(original.nodes()) else 0. for k in list(ruleGraph.nodes())})
            impactScore = nx.get_node_attributes(original, "impactScore")
            nx.set_node_attributes(ruleGraph,name='impactScore', values={k: impactScore[k] if k in list(original.nodes()) else 0. for k in list(ruleGraph.nodes())})
            nx.write_graphml(ruleGraph,subpop[:-1]+"_cellular_senesence_hsa04218_ruleGraph.graphml")

    """

    # Make network figures: 3c, 4c - UPDATED
    subpopNames = {
        "11_subpop": "T cells CD8/NK cells resting",
        "14_subpop": "Monocytes",
    }  # {"0_subpop" : "B cells naive - 1", "1_subpop" : "T cells CD8 - 1", "2_subpop" : "T cells CD4 - 1", "3_subpop" : "T cells CD8/CD4/CD4 naive", "4_subpop" : "T cells CD8 naive/T cells CD8/ RBCs", "5_subpop" : "B cells naive - 2", "6_subpop" : "T cells naive", "7_subpop" : "T cells CD8 - 2", "8_subpop" : "T cells CD8 - 3", "9_subpop" : "NK cells resting", "10_subpop"  : "T cells CD8 - 4", "11_subpop" : "T cells CD8/NK cells resting", "12_subpop" : "T cells CD4 memory resting/ T cells CD8", "13_subpop" : "B cells memory", "14_subpop" : "Monocytes", "15_subpop" : "NK cells activated"}
    paths = glob.glob("*/")
    mainDir = os.getcwd()
    for subpop in paths:
        if str(subpop)[:-1] in subpopNames.keys():
            print(subpop)
            os.chdir(subpop)
            compareSubpops()
            ruleFile = glob.glob("*_rule_analysis.csv")
            print(ruleFile)
            rule_analysis_file = pd.read_csv(
                ruleFile[0]
            )  # these files come from compareSubpops_scBonita.py
            networksOfInterest = [
                "hsa04024.graphml",
                "hsa04630.graphml",
            ]  # glob.glob("*.graphml")#["hsa04151.graphml", "hsa04024.graphml", "hsa04670.graphml", "hsa04630.graphml", "hsa04066.graphml", "hsa04933.graphml", "hsa04810.graphml","hsa04360.graphml","hsa04218.graphml","hsa04360.graphml"]
            for network in networksOfInterest:
                if os.path.exists(network[0:8] + "_IS_AS_vs_nonAS.graphml"):
                    print(network)
                    rule_analysis_network = rule_analysis_file.loc[
                        rule_analysis_file.Graph == network, :
                    ]
                    rule_analysis_network.loc[
                        :, "plainEquivs"
                    ] = rule_analysis_network.plainEquivs.str.replace(
                        pat="{", repl="[", regex=True
                    )
                    rule_analysis_network.loc[
                        :, "plainEquivs"
                    ] = rule_analysis_network.plainEquivs.str.replace(
                        pat="}", repl="]", regex=True
                    )
                    rule_analysis_network.loc[:, "plainEquivs"] = [
                        literal_eval(temp)
                        for temp in rule_analysis_network.plainEquivs.tolist()
                    ]
                    sampledRules = [
                        choice(temp)
                        for temp in rule_analysis_network.plainEquivs.tolist()
                    ]
                    ruleGraph = Get_expanded_network(sampledRules, equal_sign="*=")
                    ruleGraph = nx.relabel_nodes(
                        ruleGraph, lambda x: x.replace(" ", "")
                    )
                    original = nx.read_graphml(network[0:8] + "_IS_AS_vs_nonAS.graphml")
                    nx.set_node_attributes(
                        original,
                        name="Display Name",
                        values={k: k.replace(" ", "") for k in original.nodes()},
                    )
                    nx.set_node_attributes(
                        original,
                        name="andNode",
                        values={k: 0 for k in original.nodes()},
                    )
                    RAval = nx.get_node_attributes(original, "relativeAbundance")
                    nx.set_node_attributes(
                        ruleGraph,
                        name="relativeAbundance",
                        values={
                            k: RAval[k] if k in list(original.nodes()) else 0.0
                            for k in list(ruleGraph.nodes())
                        },
                    )
                    pathImportances = nx.get_node_attributes(original, "Strat3_IS")
                    print(pathImportances)
                    nx.set_node_attributes(
                        ruleGraph,
                        name="importanceScore",
                        values={
                            k: pathImportances[k]
                            if k in list(original.nodes())
                            else 0.0
                            for k in list(ruleGraph.nodes())
                        },
                    )
                    DisplayName = nx.get_node_attributes(original, "Display Name")
                    nx.set_node_attributes(
                        ruleGraph,
                        name="Display Name",
                        values={
                            k: DisplayName[k] if k in list(original.nodes()) else "&"
                            for k in list(ruleGraph.nodes())
                        },
                    )
                    nx.write_graphml_lxml(
                        ruleGraph,
                        str(subpop)[:-1] + "_" + network[0:8] + "_ruleGraph.graphml",
                    )
            os.chdir(mainDir)

    """
    #Make Figure 4a: boxplot showing ERS sizes by network and subpop - R script

    #Make figure 5b - UMAP plots showing networks colored by attractors
    #Note - attractors are from rules inferred for the whole dataset
    networkList = glob.glob('/gpfs/fs2/scratch/mpalshik/completeData_17July2020/graphmls/*.graphml')#('/mnt/d/GitHub/fuzzyRNA/completeData_17July2020/graphmls/*.graphml')
    networkList = [temp[-16:] for temp in networkList]
    networkList = [temp[:-8] for temp in networkList]
    print(networkList)
    makeUMAPplots_byAttractor(networkList)
    """
